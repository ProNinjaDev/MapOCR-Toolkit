# MapOCR Toolkit: Автоматическая аннотация картографических справочников

Этот репозиторий содержит инструменты для автоматической обработки изображений картографических справочников с целью извлечения, аннотации и классификации текстовой информации. Проект направлен на решение проблемы шумов и искажений в отсканированных картах для улучшения качества распознавания текста и последующего анализа.

## Описание проблемы

Картографические справочники часто содержат изображения с различными дефектами (цветовые артефакты, пикселизация, размытость, низкий контраст), возникающими из-за качества печати или процесса сканирования. Эти дефекты значительно усложняют автоматическое распознавание текста (OCR) и анализ стилистических особенностей шрифта, которые важны для классификации географических объектов.

## Текущее состояние

На данный момент реализован **модуль очистки изображений** от шумов. Этот модуль использует алгоритм, основанный на **Random Forest Regression (RFR)**, для улучшения четкости и читаемости текста на изображениях. Метод вдохновлен техникой шумоподавления Колина Приста и использует технику скользящего окна для подготовки обучающих данных.

**Основные компоненты:**

*   `image_processing`: Функции для загрузки, базовой обработки и сохранения изображений.
*   `clean_image.py`: Реализация алгоритма шумоподавления RFR для отдельных изображений.
*   `train_cleaner.py`: Обучение модели RFR на подготовленных данных.
*   `pdf_cleaner.py`: Обработка PDF-документов (извлечение страниц как изображений и их очистка).
*   `config`: Файл конфигурации для параметров программы (пути, параметры модели и т.д.).

## Планы на будущее

Следующие этапы разработки включают:

1.  **Интеграция OCR:**
    *   Использование Tesseract OCR (или аналогов) для извлечения текста с очищенных изображений.
    *   Определение координат текстовых блоков.
    *   Анализ форматирования текста (размер, курсив, жирность), если OCR-движок это позволяет.
2.  **Классификация и аннотация текста:**
    *   Разработка модели на основе нейронных сетей (CNN для анализа стиля, RNN/LSTM для анализа содержания текста, возможно, комбинированная архитектура CNN-LSTM).
    *   Автоматическое определение типа объекта (город, река, улица и т.д.) на основе извлеченных признаков.
    *   Формирование структурированного вывода: `[текст, тип_объекта, координаты]`.
3.  **Визуализация:**
    *   Отображение аннотированной информации на исходном изображении (рамки, метки).
    *   Сохранение результатов в виде аннотированных изображений и/или табличных данных.

## Настройка для разработчиков

1.  **Клонируйте репозиторий:**
    ```bash
    git clone <URL_репозитория>
    cd <папка_репозитория>
    ```
2.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Обучение модели:**
    *   Подготовьте наборы "чистых" и "зашумленных" изображений.
    *   Запустите скрипт `train_cleaner.py` (возможно, потребуется адаптация путей в `config`).
4.  **Использование:**
    *   Настройте пути в файле `config`.
    *   Используйте `clean_image.py` для очистки отдельных изображений или `pdf_cleaner.py` для обработки PDF-файлов.

## Использованные технологии

*   Python
*   OpenCV
*   Scikit-learn
*   Imutils
*   NumPy
*   (Планируется) Tesseract OCR, TensorFlow/PyTorch
